'use client'

import { createContext, useContext, useState, ReactNode } from 'react'

type Language = 'en' | 'fr'

interface Translations {
  [key: string]: {
    en: string
    fr: string
  }
}

const translations: Translations = {
  // Main page
  'title': { en: 'Machine Learning Models Explained', fr: 'ModÃ¨les d\'Apprentissage Automatique ExpliquÃ©s' },
  'subtitle': { en: 'Interactive visualizations of ad click prediction models', fr: 'Visualisations interactives des modÃ¨les de prÃ©diction de clics publicitaires' },
  'selectModel': { en: 'Select a Model to Explore', fr: 'SÃ©lectionnez un ModÃ¨le Ã  Explorer' },
  'selectModelDesc': { en: 'Choose one of the machine learning models from the grid above to see an interactive visualization explaining how it thinks and makes predictions.', fr: 'Choisissez l\'un des modÃ¨les d\'apprentissage automatique dans la grille ci-dessus pour voir une visualisation interactive expliquant comment il pense et fait des prÃ©dictions.' },
  'clickToExplore': { en: 'Click to explore', fr: 'Cliquez pour explorer' },
  'clickToClose': { en: 'Click to close', fr: 'Cliquez pour fermer' },
  'step': { en: 'Step', fr: 'Ã‰tape' },
  'click': { en: 'Click', fr: 'Clic' },
  'noClick': { en: 'No Click', fr: 'Pas de Clic' },

  // Logistic Regression
  'lr.title': { en: 'Logistic Regression', fr: 'RÃ©gression Logistique' },
  'lr.subtitle': { en: 'A linear model that uses the sigmoid function to predict probabilities', fr: 'Un modÃ¨le linÃ©aire qui utilise la fonction sigmoÃ¯de pour prÃ©dire les probabilitÃ©s' },
  'lr.step1.title': { en: 'Linear Combination', fr: 'Combinaison LinÃ©aire' },
  'lr.step1.desc': { en: 'The model combines features with weights to create a linear score (z)', fr: 'Le modÃ¨le combine les caractÃ©ristiques avec des poids pour crÃ©er un score linÃ©aire (z)' },
  'lr.step1.formula': { en: 'z = wâ‚Ã—age + wâ‚‚Ã—device + wâ‚ƒÃ—time + b', fr: 'z = wâ‚Ã—Ã¢ge + wâ‚‚Ã—appareil + wâ‚ƒÃ—heure + b' },
  'lr.step2.title': { en: 'Sigmoid Transformation', fr: 'Transformation SigmoÃ¯de' },
  'lr.step2.desc': { en: 'The sigmoid function converts the linear score into a probability between 0 and 1', fr: 'La fonction sigmoÃ¯de convertit le score linÃ©aire en une probabilitÃ© entre 0 et 1' },
  'lr.step2.formula': { en: 'P(click) = 1 / (1 + e^(-z))', fr: 'P(clic) = 1 / (1 + e^(-z))' },
  'lr.step3.title': { en: 'Decision Threshold', fr: 'Seuil de DÃ©cision' },
  'lr.step3.desc': { en: 'If probability > 0.5, predict "click", otherwise predict "no click"', fr: 'Si probabilitÃ© > 0.5, prÃ©dire "clic", sinon prÃ©dire "pas de clic"' },
  'lr.step3.formula': { en: 'Prediction = P(click) > 0.5 ? Click : No Click', fr: 'PrÃ©diction = P(clic) > 0.5 ? Clic : Pas de Clic' },
  'lr.sigmoid.title': { en: 'Sigmoid Function Visualization', fr: 'Visualisation de la Fonction SigmoÃ¯de' },
  'lr.sigmoid.desc': { en: 'The S-shaped curve ensures probabilities stay between 0 and 1', fr: 'La courbe en forme de S garantit que les probabilitÃ©s restent entre 0 et 1' },
  'lr.weights.title': { en: 'Adjust Feature Weights', fr: 'Ajuster les Poids des CaractÃ©ristiques' },
  'lr.prediction': { en: 'Predicted Click Probability', fr: 'ProbabilitÃ© de Clic PrÃ©dite' },
  'lr.interpretable': { en: 'âœ“ Interpretable', fr: 'âœ“ InterprÃ©table' },
  'lr.interpretable.desc': { en: 'Easy to understand feature importance', fr: 'Facile de comprendre l\'importance des caractÃ©ristiques' },
  'lr.fast': { en: 'âš¡ Fast Training', fr: 'âš¡ EntraÃ®nement Rapide' },
  'lr.fast.desc': { en: 'Quick to train and make predictions', fr: 'Rapide Ã  entraÃ®ner et Ã  faire des prÃ©dictions' },
  'lr.probabilistic': { en: 'ðŸ“Š Probabilistic', fr: 'ðŸ“Š Probabiliste' },
  'lr.probabilistic.desc': { en: 'Provides probability scores, not just predictions', fr: 'Fournit des scores de probabilitÃ©, pas seulement des prÃ©dictions' },

  // KNN
  'knn.title': { en: 'K-Nearest Neighbors (KNN)', fr: 'K Plus Proches Voisins (KNN)' },
  'knn.subtitle': { en: 'A lazy learning algorithm that makes predictions based on similarity to training examples', fr: 'Un algorithme d\'apprentissage paresseux qui fait des prÃ©dictions basÃ©es sur la similaritÃ© aux exemples d\'entraÃ®nement' },
  'knn.kValue': { en: 'K Value (Number of Neighbors)', fr: 'Valeur K (Nombre de Voisins)' },
  'knn.kValue.desc': { en: 'Adjust K to see how it affects the prediction. Lower K = more sensitive, Higher K = more stable', fr: 'Ajustez K pour voir comment cela affecte la prÃ©diction. K plus bas = plus sensible, K plus haut = plus stable' },
  'knn.step1.title': { en: 'Find K Nearest Neighbors', fr: 'Trouver les K Plus Proches Voisins' },
  'knn.step1.desc': { en: 'The algorithm finds the {k} closest data points to the new point based on distance', fr: 'L\'algorithme trouve les {k} points de donnÃ©es les plus proches du nouveau point basÃ© sur la distance' },
  'knn.step2.title': { en: 'Count Votes', fr: 'Compter les Votes' },
  'knn.step2.desc': { en: 'Count how many of the {k} neighbors belong to each class (Click vs No Click)', fr: 'Compter combien des {k} voisins appartiennent Ã  chaque classe (Clic vs Pas de Clic)' },
  'knn.step3.title': { en: 'Make Prediction', fr: 'Faire une PrÃ©diction' },
  'knn.step3.desc': { en: 'Predict the class that has the majority vote among the {k} neighbors', fr: 'PrÃ©dire la classe qui a le vote majoritaire parmi les {k} voisins' },
  'knn.viz.title': { en: 'Interactive 2D Visualization', fr: 'Visualisation 2D Interactive' },
  'knn.legend.click': { en: 'Click', fr: 'Clic' },
  'knn.legend.noClick': { en: 'No Click', fr: 'Pas de Clic' },
  'knn.legend.neighbor': { en: 'Neighbor', fr: 'Voisin' },
  'knn.legend.newPoint': { en: 'New Point', fr: 'Nouveau Point' },
  'knn.prediction': { en: 'Prediction', fr: 'PrÃ©diction' },
  'knn.prediction.based': { en: 'Based on {count} out of {k} neighbors', fr: 'BasÃ© sur {count} sur {k} voisins' },
  'knn.simple': { en: 'ðŸŽ¯ Simple & Intuitive', fr: 'ðŸŽ¯ Simple et Intuitif' },
  'knn.simple.desc': { en: 'Easy to understand and implement', fr: 'Facile Ã  comprendre et Ã  implÃ©menter' },
  'knn.nonParametric': { en: 'ðŸ“Š Non-Parametric', fr: 'ðŸ“Š Non-ParamÃ©trique' },
  'knn.nonParametric.desc': { en: 'Makes no assumptions about data distribution', fr: 'Ne fait aucune hypothÃ¨se sur la distribution des donnÃ©es' },
  'knn.kSelection': { en: 'âš–ï¸ K Selection Matters', fr: 'âš–ï¸ La SÃ©lection de K est Importante' },
  'knn.kSelection.desc': { en: 'Choosing the right K is crucial for performance', fr: 'Choisir le bon K est crucial pour les performances' },

  // Random Forest
  'rf.title': { en: 'Random Forest', fr: 'ForÃªt AlÃ©atoire' },
  'rf.subtitle': { en: 'An ensemble method that combines multiple decision trees for robust predictions', fr: 'Une mÃ©thode d\'ensemble qui combine plusieurs arbres de dÃ©cision pour des prÃ©dictions robustes' },
  'rf.numTrees': { en: 'Number of Trees', fr: 'Nombre d\'Arbres' },
  'rf.numTrees.desc': { en: 'More trees generally improve accuracy but increase training time', fr: 'Plus d\'arbres amÃ©liorent gÃ©nÃ©ralement la prÃ©cision mais augmentent le temps d\'entraÃ®nement' },
  'rf.step1.title': { en: 'Bootstrap Sampling', fr: 'Ã‰chantillonnage Bootstrap' },
  'rf.step1.desc': { en: 'Create multiple training sets by randomly sampling with replacement', fr: 'CrÃ©er plusieurs ensembles d\'entraÃ®nement en Ã©chantillonnant alÃ©atoirement avec remplacement' },
  'rf.step2.title': { en: 'Build Decision Trees', fr: 'Construire des Arbres de DÃ©cision' },
  'rf.step2.desc': { en: 'Each tree is built on a different sample and uses random feature subsets', fr: 'Chaque arbre est construit sur un Ã©chantillon diffÃ©rent et utilise des sous-ensembles de caractÃ©ristiques alÃ©atoires' },
  'rf.step3.title': { en: 'Voting & Aggregation', fr: 'Vote et AgrÃ©gation' },
  'rf.step3.desc': { en: 'All trees vote on the prediction, and the majority vote wins', fr: 'Tous les arbres votent sur la prÃ©diction, et le vote majoritaire l\'emporte' },
  'rf.trees.title': { en: 'Individual Tree Predictions', fr: 'PrÃ©dictions des Arbres Individuels' },
  'rf.trees.confident': { en: '% confident', fr: '% confiant' },
  'rf.voting.title': { en: 'Voting Process', fr: 'Processus de Vote' },
  'rf.voting.click': { en: 'Click Votes', fr: 'Votes pour Clic' },
  'rf.voting.noClick': { en: 'No Click Votes', fr: 'Votes pour Pas de Clic' },
  'rf.final.title': { en: 'Final Prediction (Majority Vote)', fr: 'PrÃ©diction Finale (Vote Majoritaire)' },
  'rf.final.confidence': { en: 'Confidence:', fr: 'Confiance:' },
  'rf.overfitting': { en: 'ðŸŒ³ Reduces Overfitting', fr: 'ðŸŒ³ RÃ©duit le Surapprentissage' },
  'rf.overfitting.desc': { en: 'Averaging multiple trees reduces variance', fr: 'La moyenne de plusieurs arbres rÃ©duit la variance' },
  'rf.importance': { en: 'ðŸ“Š Feature Importance', fr: 'ðŸ“Š Importance des CaractÃ©ristiques' },
  'rf.importance.desc': { en: 'Can identify which features matter most', fr: 'Peut identifier quelles caractÃ©ristiques sont les plus importantes' },
  'rf.nonlinearity': { en: 'âš¡ Handles Non-linearity', fr: 'âš¡ GÃ¨re la Non-linÃ©aritÃ©' },
  'rf.nonlinearity.desc': { en: 'Can capture complex feature interactions', fr: 'Peut capturer des interactions complexes de caractÃ©ristiques' },

  // XGBoost
  'xgb.title': { en: 'XGBoost (Extreme Gradient Boosting)', fr: 'XGBoost (Gradient Boosting ExtrÃªme)' },
  'xgb.subtitle': { en: 'An advanced gradient boosting algorithm that builds trees sequentially to minimize errors', fr: 'Un algorithme de gradient boosting avancÃ© qui construit des arbres sÃ©quentiellement pour minimiser les erreurs' },
  'xgb.numTrees': { en: 'Number of Trees', fr: 'Nombre d\'Arbres' },
  'xgb.learningRate': { en: 'Learning Rate', fr: 'Taux d\'Apprentissage' },
  'xgb.learningRate.desc': { en: 'Lower rate = more conservative, slower learning', fr: 'Taux plus bas = plus conservateur, apprentissage plus lent' },
  'xgb.step1.title': { en: 'Sequential Tree Building', fr: 'Construction SÃ©quentielle d\'Arbres' },
  'xgb.step1.desc': { en: 'Trees are built sequentially, where each new tree corrects errors made by previous trees', fr: 'Les arbres sont construits sÃ©quentiellement, oÃ¹ chaque nouvel arbre corrige les erreurs faites par les arbres prÃ©cÃ©dents' },
  'xgb.step2.title': { en: 'Gradient Boosting', fr: 'Gradient Boosting' },
  'xgb.step2.desc': { en: 'Uses gradient descent to minimize prediction errors by focusing on difficult examples', fr: 'Utilise la descente de gradient pour minimiser les erreurs de prÃ©diction en se concentrant sur les exemples difficiles' },
  'xgb.step3.title': { en: 'Weighted Combination', fr: 'Combinaison PondÃ©rÃ©e' },
  'xgb.step3.desc': { en: 'Final prediction is a weighted sum of all tree predictions, with later trees having more weight', fr: 'La prÃ©diction finale est une somme pondÃ©rÃ©e de toutes les prÃ©dictions d\'arbres, les arbres plus rÃ©cents ayant plus de poids' },
  'xgb.sequential.title': { en: 'Sequential Tree Building', fr: 'Construction SÃ©quentielle d\'Arbres' },
  'xgb.sequential.tree': { en: 'Tree', fr: 'Arbre' },
  'xgb.sequential.error': { en: 'Error:', fr: 'Erreur:' },
  'xgb.loss.title': { en: 'Training Loss Over Iterations', fr: 'Perte d\'EntraÃ®nement sur les ItÃ©rations' },
  'xgb.loss.desc': { en: 'Loss decreases as each new tree corrects previous errors', fr: 'La perte diminue Ã  mesure que chaque nouvel arbre corrige les erreurs prÃ©cÃ©dentes' },
  'xgb.formula.title': { en: 'How Predictions Are Made', fr: 'Comment les PrÃ©dictions sont Faites' },
  'xgb.formula.eq': { en: 'Prediction = Treeâ‚ + Treeâ‚‚ + Treeâ‚ƒ + ... + Treeâ‚™', fr: 'PrÃ©diction = Arbreâ‚ + Arbreâ‚‚ + Arbreâ‚ƒ + ... + Arbreâ‚™' },
  'xgb.formula.point1': { en: 'â€¢ Each tree makes a prediction (residual correction)', fr: 'â€¢ Chaque arbre fait une prÃ©diction (correction rÃ©siduelle)' },
  'xgb.formula.point2': { en: 'â€¢ Predictions are summed together', fr: 'â€¢ Les prÃ©dictions sont additionnÃ©es' },
  'xgb.formula.point3': { en: 'â€¢ Learning rate ({rate}) controls how much each tree contributes', fr: 'â€¢ Le taux d\'apprentissage ({rate}) contrÃ´le la contribution de chaque arbre' },
  'xgb.formula.point4': { en: 'â€¢ Final prediction = weighted sum of all tree predictions', fr: 'â€¢ PrÃ©diction finale = somme pondÃ©rÃ©e de toutes les prÃ©dictions d\'arbres' },
  'xgb.performance': { en: 'ðŸ† High Performance', fr: 'ðŸ† Haute Performance' },
  'xgb.performance.desc': { en: 'Often achieves state-of-the-art results', fr: 'Atteint souvent des rÃ©sultats de pointe' },
  'xgb.fast': { en: 'âš¡ Fast Training', fr: 'âš¡ EntraÃ®nement Rapide' },
  'xgb.fast.desc': { en: 'Optimized for speed and efficiency', fr: 'OptimisÃ© pour la vitesse et l\'efficacitÃ©' },
  'xgb.error': { en: 'ðŸŽ¯ Error Correction', fr: 'ðŸŽ¯ Correction d\'Erreur' },
  'xgb.error.desc': { en: 'Each tree focuses on previous mistakes', fr: 'Chaque arbre se concentre sur les erreurs prÃ©cÃ©dentes' },
  'xgb.treeGrowth.title': { en: 'Level-wise Tree Growth', fr: 'Croissance d\'Arbre Niveau par Niveau' },
  'xgb.treeGrowth.desc': { en: 'XGBoost grows trees level by level. All nodes at level 0 are created first, then all nodes at level 1, and so on. This ensures balanced trees.', fr: 'XGBoost fait pousser les arbres niveau par niveau. Tous les nÅ“uds au niveau 0 sont crÃ©Ã©s en premier, puis tous les nÅ“uds au niveau 1, et ainsi de suite. Cela garantit des arbres Ã©quilibrÃ©s.' },
  'xgb.treeGrowth.level': { en: 'Level', fr: 'Niveau' },
  'xgb.treeGrowth.animating': { en: 'Growing level by level...', fr: 'Croissance niveau par niveau...' },

  // LightGBM
  'lgbm.title': { en: 'LightGBM', fr: 'LightGBM' },
  'lgbm.subtitle': { en: 'A fast, distributed gradient boosting framework optimized for efficiency and accuracy', fr: 'Un framework de gradient boosting rapide et distribuÃ© optimisÃ© pour l\'efficacitÃ© et la prÃ©cision' },
  'lgbm.hyperparams.title': { en: 'Hyperparameters', fr: 'HyperparamÃ¨tres' },
  'lgbm.hyperparams.desc': { en: 'Adjust these parameters to control how LightGBM learns. Each parameter affects model performance differently.', fr: 'Ajustez ces paramÃ¨tres pour contrÃ´ler comment LightGBM apprend. Chaque paramÃ¨tre affecte les performances du modÃ¨le diffÃ©remment.' },
  'lgbm.nEstimators.title': { en: 'n_estimators', fr: 'n_estimators' },
  'lgbm.nEstimators.desc': { en: 'Number of boosting rounds (trees) to build', fr: 'Nombre de tours de boosting (arbres) Ã  construire' },
  'lgbm.nEstimators.effect': { en: 'Effect:', fr: 'Effet:' },
  'lgbm.nEstimators.effect.desc': { en: 'More trees = better accuracy but slower training. Too many can cause overfitting.', fr: 'Plus d\'arbres = meilleure prÃ©cision mais entraÃ®nement plus lent. Trop peut causer du surapprentissage.' },
  'lgbm.maxDepth.title': { en: 'max_depth', fr: 'max_depth' },
  'lgbm.maxDepth.desc': { en: 'Maximum depth of each decision tree', fr: 'Profondeur maximale de chaque arbre de dÃ©cision' },
  'lgbm.maxDepth.effect': { en: 'Effect:', fr: 'Effet:' },
  'lgbm.maxDepth.effect.desc': { en: 'Deeper trees = more complex patterns but risk of overfitting. Shallower = faster, simpler models.', fr: 'Arbres plus profonds = modÃ¨les plus complexes mais risque de surapprentissage. Plus superficiels = plus rapides, modÃ¨les plus simples.' },
  'lgbm.learningRate.title': { en: 'learning_rate', fr: 'learning_rate' },
  'lgbm.learningRate.desc': { en: 'Step size for each tree\'s contribution to the final prediction', fr: 'Taille du pas pour la contribution de chaque arbre Ã  la prÃ©diction finale' },
  'lgbm.learningRate.effect': { en: 'Effect:', fr: 'Effet:' },
  'lgbm.learningRate.effect.desc': { en: 'Lower rate = slower learning, more stable. Higher rate = faster learning, may overshoot optimal solution.', fr: 'Taux plus bas = apprentissage plus lent, plus stable. Taux plus Ã©levÃ© = apprentissage plus rapide, peut dÃ©passer la solution optimale.' },
  'lgbm.numLeaves': { en: 'num_leaves', fr: 'num_leaves' },
  'lgbm.numLeaves.desc': { en: 'Maximum number of leaves in one tree (LightGBM specific)', fr: 'Nombre maximum de feuilles dans un arbre (spÃ©cifique Ã  LightGBM)' },
  'lgbm.numLeaves.effect': { en: 'Effect:', fr: 'Effet:' },
  'lgbm.numLeaves.effect.desc': { en: 'More leaves = more complex trees, better fit but slower and risk of overfitting. This is the main parameter for controlling tree complexity in LightGBM.', fr: 'Plus de feuilles = arbres plus complexes, meilleur ajustement mais plus lent et risque de surapprentissage. C\'est le paramÃ¨tre principal pour contrÃ´ler la complexitÃ© des arbres dans LightGBM.' },
  'lgbm.sequential.title': { en: 'Sequential Tree Building', fr: 'Construction SÃ©quentielle d\'Arbres' },
  'lgbm.sequential.desc': { en: 'LightGBM builds trees one after another. Each new tree focuses on correcting errors made by previous trees.', fr: 'LightGBM construit les arbres un aprÃ¨s l\'autre. Chaque nouvel arbre se concentre sur la correction des erreurs faites par les arbres prÃ©cÃ©dents.' },
  'lgbm.sequential.tree': { en: 'Tree', fr: 'Arbre' },
  'lgbm.sequential.error': { en: 'Error:', fr: 'Erreur:' },
  'lgbm.loss.title': { en: 'Loss Reduction Over Iterations', fr: 'RÃ©duction de Perte sur les ItÃ©rations' },
  'lgbm.loss.desc': { en: 'As each tree is added, the overall prediction error decreases', fr: 'Ã€ mesure que chaque arbre est ajoutÃ©, l\'erreur de prÃ©diction globale diminue' },
  'lgbm.prediction.title': { en: 'How Predictions Are Made', fr: 'Comment les PrÃ©dictions sont Faites' },
  'lgbm.prediction.desc': { en: 'LightGBM combines predictions from all trees. Each tree makes a small correction, and together they create an accurate prediction.', fr: 'LightGBM combine les prÃ©dictions de tous les arbres. Chaque arbre fait une petite correction, et ensemble ils crÃ©ent une prÃ©diction prÃ©cise.' },
  'lgbm.prediction.formula': { en: 'Final Prediction = Treeâ‚ + Treeâ‚‚ + Treeâ‚ƒ + ... + Treeâ‚™', fr: 'PrÃ©diction Finale = Arbreâ‚ + Arbreâ‚‚ + Arbreâ‚ƒ + ... + Arbreâ‚™' },
  'lgbm.treeGrowth.title': { en: 'Leaf-wise Tree Growth', fr: 'Croissance d\'Arbre Feuille par Feuille' },
  'lgbm.treeGrowth.desc': { en: 'LightGBM grows trees leaf-wise. It finds the leaf with the largest loss reduction and splits it, creating a complete path to a new leaf before expanding other branches. This creates deeper, more efficient trees.', fr: 'LightGBM fait pousser les arbres feuille par feuille. Il trouve la feuille avec la plus grande rÃ©duction de perte et la divise, crÃ©ant un chemin complet vers une nouvelle feuille avant d\'Ã©tendre d\'autres branches. Cela crÃ©e des arbres plus profonds et plus efficaces.' },
  'lgbm.treeGrowth.animating': { en: 'Growing leaf by leaf...', fr: 'Croissance feuille par feuille...' },
  'lgbm.treeGrowth.split': { en: 'Splitting leaf with max loss reduction', fr: 'Division de la feuille avec la plus grande rÃ©duction de perte' },
  'lgbm.advantages.title': { en: 'Key Advantages', fr: 'Avantages ClÃ©s' },
  'lgbm.faster': { en: 'âš¡ Faster Training', fr: 'âš¡ EntraÃ®nement Plus Rapide' },
  'lgbm.faster.desc': { en: 'Up to 10x faster than XGBoost due to leaf-wise growth and feature bundling', fr: 'Jusqu\'Ã  10x plus rapide que XGBoost grÃ¢ce Ã  la croissance feuille par feuille et au regroupement de caractÃ©ristiques' },
  'lgbm.memory': { en: 'ðŸŒ¿ Lower Memory', fr: 'ðŸŒ¿ Moins de MÃ©moire' },
  'lgbm.memory.desc': { en: 'More memory efficient, can handle larger datasets', fr: 'Plus efficace en mÃ©moire, peut gÃ©rer des ensembles de donnÃ©es plus volumineux' },
  'lgbm.accuracy': { en: 'ðŸ“‰ Better Accuracy', fr: 'ðŸ“‰ Meilleure PrÃ©cision' },
  'lgbm.accuracy.desc': { en: 'Often achieves better accuracy with fewer trees', fr: 'Atteint souvent une meilleure prÃ©cision avec moins d\'arbres' },

  // Decision Tree
  'dt.title': { en: 'Decision Tree', fr: 'Arbre de DÃ©cision' },
  'dt.subtitle': { en: 'A simple tree-based model that makes decisions by asking questions about features', fr: 'Un modÃ¨le simple basÃ© sur des arbres qui prend des dÃ©cisions en posant des questions sur les caractÃ©ristiques' },

  // Ensemble
  'ensemble.title': { en: 'Ensemble Model (Voting Classifier)', fr: 'ModÃ¨le d\'Ensemble (Classifieur de Vote)' },
  'ensemble.subtitle': { en: 'Combines predictions from multiple models to achieve better accuracy and robustness', fr: 'Combine les prÃ©dictions de plusieurs modÃ¨les pour atteindre une meilleure prÃ©cision et robustesse' },
  'ensemble.voting.title': { en: 'Voting Strategy', fr: 'StratÃ©gie de Vote' },
  'ensemble.voting.hard': { en: 'Hard Voting', fr: 'Vote Dur' },
  'ensemble.voting.hard.desc': { en: 'Each model votes for a class, majority wins', fr: 'Chaque modÃ¨le vote pour une classe, la majoritÃ© l\'emporte' },
  'ensemble.voting.soft': { en: 'Soft Voting', fr: 'Vote Doux' },
  'ensemble.voting.soft.desc': { en: 'Averages probability scores from all models', fr: 'Moyenne des scores de probabilitÃ© de tous les modÃ¨les' },
  'ensemble.select.title': { en: 'Select Models for Ensemble', fr: 'SÃ©lectionner les ModÃ¨les pour l\'Ensemble' },
  'ensemble.select.active': { en: 'âœ“ Active', fr: 'âœ“ Actif' },
  'ensemble.select.inactive': { en: 'Inactive', fr: 'Inactif' },
  'ensemble.predictions.title': { en: 'Individual Model Predictions', fr: 'PrÃ©dictions des ModÃ¨les Individuels' },
  'ensemble.votingProcess.title': { en: 'Voting Process', fr: 'Processus de Vote' },
  'ensemble.votingProcess.hard': { en: 'Hard Voting Process', fr: 'Processus de Vote Dur' },
  'ensemble.votingProcess.soft': { en: 'Soft Voting Process', fr: 'Processus de Vote Doux' },
  'ensemble.votingProcess.click': { en: 'Click Votes', fr: 'Votes pour Clic' },
  'ensemble.votingProcess.noClick': { en: 'No Click Votes', fr: 'Votes pour Pas de Clic' },
  'ensemble.votingProcess.avg': { en: 'Average Probability', fr: 'ProbabilitÃ© Moyenne' },
  'ensemble.final.title': { en: 'Ensemble Prediction ({type} voting)', fr: 'PrÃ©diction d\'Ensemble (vote {type})' },
  'ensemble.final.confidence': { en: 'Confidence:', fr: 'Confiance:' },
  'ensemble.final.based': { en: 'Based on {count} model{plural}', fr: 'BasÃ© sur {count} modÃ¨le{plural}' },
  'ensemble.robust': { en: 'ðŸ›¡ï¸ More Robust', fr: 'ðŸ›¡ï¸ Plus Robuste' },
  'ensemble.robust.desc': { en: 'Reduces risk of relying on a single model\'s weaknesses', fr: 'RÃ©duit le risque de s\'appuyer sur les faiblesses d\'un seul modÃ¨le' },
  'ensemble.better': { en: 'ðŸ“ˆ Better Accuracy', fr: 'ðŸ“ˆ Meilleure PrÃ©cision' },
  'ensemble.better.desc': { en: 'Often outperforms individual models through diversity', fr: 'Surpasse souvent les modÃ¨les individuels grÃ¢ce Ã  la diversitÃ©' },
  'ensemble.diversity': { en: 'ðŸ‘¥ Diversity', fr: 'ðŸ‘¥ DiversitÃ©' },
  'ensemble.diversity.desc': { en: 'Different models capture different patterns in the data', fr: 'DiffÃ©rents modÃ¨les capturent diffÃ©rents modÃ¨les dans les donnÃ©es' },
}

interface TranslationContextType {
  language: Language
  setLanguage: (lang: Language) => void
  t: (key: string, params?: Record<string, string | number>) => string
}

const TranslationContext = createContext<TranslationContextType | undefined>(undefined)

export function TranslationProvider({ children }: { children: ReactNode }) {
  const [language, setLanguage] = useState<Language>('en')

  const t = (key: string, params?: Record<string, string | number>): string => {
    const translation = translations[key]?.[language] || translations[key]?.en || key
    
    if (params) {
      return Object.entries(params).reduce((str, [param, value]) => {
        return str.replace(new RegExp(`\\{${param}\\}`, 'g'), String(value))
      }, translation)
    }
    
    return translation
  }

  return (
    <TranslationContext.Provider value={{ language, setLanguage, t }}>
      {children}
    </TranslationContext.Provider>
  )
}

export function useTranslation() {
  const context = useContext(TranslationContext)
  if (!context) {
    throw new Error('useTranslation must be used within TranslationProvider')
  }
  return context
}

